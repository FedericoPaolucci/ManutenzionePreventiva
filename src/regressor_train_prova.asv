clc;
load('koopman_features.mat'); % contiene X_features, y_targets
load('koopman_test_features.mat') % test
%% Oversampling manuale delle classi (moltiplichiamo i sample)
idx_0 = find(y_targets == 0);
idx_1 = find(y_targets == 1);
idx_2 = find(y_targets == 2);
idx_3 = find(y_targets == 3);
idx_4 = find(y_targets == 4);
idx_6 = find(y_targets == 6);
idx_8 = find(y_targets == 8);

% Funzione helper: oversampling con duplicazione
augment = @(X, y, n) deal(repmat(X, n, 1), repmat(y, n, 1));
% Funzione helper: oversampling con rumore
augment_noise = @(X, y, n, noise) deal(repmat(X, n, 1) + noise * randn(size(repmat(X, n, 1))), repmat(y, n, 1));

% 🔁 Oversampling semplice per alcune classi
[X_aug0, y_aug0] = augment(X_features(idx_0,:), y_targets(idx_0), 10);
[X_aug1, y_aug1] = augment(X_features(idx_1,:), y_targets(idx_1), 8);
[X_aug2, y_aug2] = augment(X_features(idx_2,:), y_targets(idx_2), 5);
[X_aug3, y_aug3] = augment(X_features(idx_3,:), y_targets(idx_3), 5);
[X_aug4, y_aug4] = augment(X_features(idx_4,:), y_targets(idx_4), 5);
[X_aug6, y_aug6] = augment(X_features(idx_6,:), y_targets(idx_6), 8);
[X_aug8, y_aug8] = augment(X_features(idx_8,:), y_targets(idx_8), 10);

%% 🔗 3. Crea dataset esteso
X_augmented = [X_features; X_aug0; X_aug1; X_aug2; X_aug3; X_aug4; X_aug6; X_aug8];
y_augmented = [y_targets; y_aug0; y_aug1; y_aug2; y_aug3; y_aug4; y_aug6; y_aug8];

%% 🔍 4. Normalizza le feature
X_augmented = normalize(X_augmented);
X_features_test = normalize(X_features_test);

%% Divisione 80-20 stratificata
cv = cvpartition(y_augmented, 'HoldOut', 0.2, 'Stratify', true);
X_train = X_augmented(training(cv), :);
y_train = y_augmented(training(cv));
X_val   = X_augmented(test(cv), :);
y_val   = y_augmented(test(cv));

%% 🧠 6. Addestramento modello
disp("✅ Addestramento fitrensemble...");
template = templateTree('MaxNumSplits', 300, 'MinLeafSize', 5);

model_ensemble = fitrensemble(X_train, y_train, 'Method', 'Bag', 'NumLearningCycles', 200, 'Learners');


%% 🧪 7. Valutazione
y_val_pred_ensemble = predict(model_ensemble, X_val);

% Valori di errore
fprintf("📉 Errore fitrensemble: MAE = %.4f | RMSE = %.4f\n", ...
    mean(abs(y_val - y_val_pred_ensemble)), sqrt(mean((y_val - y_val_pred_ensemble).^2)));

%% 📈 8. Plot Reale vs Predetto ordinato - fitrnet e fitrensemble
[~, sort_idx] = sort(y_val);
y_val_sorted = y_val(sort_idx);
y_val_pred_ensemble_sorted = y_val_pred_ensemble(sort_idx);

% 🔵 Plot per fitrensemble
figure('Name', 'Reale vs Predetto - fitrensemble');
plot(y_val_sorted, 'k-', 'LineWidth', 1.5); hold on;
plot(y_val_pred_ensemble_sorted, 'b--', 'LineWidth', 1.5);
legend('Reale', 'Predetto (fitrensemble)');
xlabel('Campione (ordinato per y\_val)');
ylabel('Health State');
title('Confronto Reale vs Predetto - fitrensemble');
grid on;

%% 🔎 9. Matrici di Confusione - entrambi i modelli

% Arrotonda valori per confronto categoria
y_val_rounded = max(0, min(10, round(y_val)));
y_pred_ens_rounded = max(0, min(10, round(y_val_pred_ensemble)));
classes = 0:10;

% 🔵 Confusion matrix - fitrensemble
figure('Name','Confusione - fitrensemble');
cm_ens = confusionchart(y_val_rounded, y_pred_ens_rounded, ...
    'RowSummary','row-normalized', ...
    'ColumnSummary','column-normalized', ...
    'Title','Matrice di Confusione (Validation) - fitrensemble', ...
    'XLabel','Predetto', 'YLabel','Reale');

%% 📦 10. Predizione test set e CSV con fitrensemble
y_test_pred = predict(model_ensemble, X_features_test);

val_errors = y_val - y_val_pred_ensemble;
mu_err = mean(val_errors);
b_err = std(val_errors) / sqrt(2);  % Laplace scale parameter

x_vals = 0:10;
num_samples = size(X_features_test, 1);
output_matrix = zeros(num_samples, 13);  % [ID, Prob_0 ... Prob_10, Confidence]

for i = 1:num_samples
    probs = exp(-abs(x_vals - y_test_pred(i)) / b_err);  % Laplace
    probs = probs / sum(probs);  % normalizzazione

    entropy_val = -sum(probs .* log(probs + eps));
    confidence = double(entropy_val < 2.0);

    output_matrix(i,:) = [i, probs, confidence];
end

header = ["SampleID", "HealthState_0", "HealthState_1", "HealthState_2", ...
          "HealthState_3", "HealthState_4", "HealthState_5", "HealthState_6", ...
          "HealthState_7", "HealthState_8", "HealthState_9", "HealthState_10", ...
          "Confidence"];

filename = 'submission.csv';
fid = fopen(filename, 'w');
fprintf(fid, '%s,', header{1:end-1});
fprintf(fid, '%s\n', header{end});
fclose(fid);
dlmwrite(filename, output_matrix, '-append');
disp(['✅ File generato: ', filename]);